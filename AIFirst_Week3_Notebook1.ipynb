{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEX7aNSVqt1x"
      },
      "source": [
        "# Let's install the Following :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLMsZh_pnAVc",
        "outputId": "0d2c119f-c488-498d-9e67-a66637f556fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution ~angchain (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~angchain (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.82.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~angchain (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Update OpenAI to latest version\n",
        "!pip install --upgrade openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vtEUReeq08K"
      },
      "source": [
        "# OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xwpuXg5lGz8q"
      },
      "outputs": [],
      "source": [
        "import openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sElZXLyXRhSS",
        "outputId": "8821e3b9-b439-43e2-f0b2-6bf5667022db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gpt-4o-mini-transcribe\n",
            "dall-e-2\n",
            "gpt-4o-mini-2024-07-18\n",
            "gpt-4o-mini\n",
            "babbage-002\n",
            "gpt-4o-2024-11-20\n",
            "whisper-1\n",
            "gpt-4o-mini-search-preview\n",
            "gpt-4o-mini-search-preview-2025-03-11\n",
            "davinci-002\n",
            "tts-1-hd\n",
            "gpt-4.1-2025-04-14\n",
            "gpt-4-turbo\n",
            "gpt-4-turbo-2024-04-09\n",
            "o3-mini-2025-01-31\n",
            "gpt-4.1\n",
            "gpt-3.5-turbo-instruct-0914\n",
            "gpt-4.1-mini-2025-04-14\n",
            "gpt-4.1-mini\n",
            "gpt-3.5-turbo-instruct\n",
            "computer-use-preview\n",
            "gpt-4o-mini-tts\n",
            "gpt-4.1-nano-2025-04-14\n",
            "text-embedding-3-small\n",
            "gpt-4o\n",
            "o3-2025-04-16\n",
            "o4-mini-2025-04-16\n",
            "gpt-4\n",
            "text-embedding-ada-002\n",
            "o1-2024-12-17\n",
            "dall-e-3\n",
            "tts-1-hd-1106\n",
            "text-embedding-3-large\n",
            "o3-mini\n",
            "gpt-4o-audio-preview\n",
            "gpt-4o-2024-05-13\n",
            "gpt-4o-search-preview-2025-03-11\n",
            "gpt-4o-search-preview\n",
            "gpt-4o-realtime-preview-2024-12-17\n",
            "gpt-3.5-turbo-16k\n",
            "o1-mini\n",
            "gpt-4-0613\n",
            "gpt-4o-realtime-preview\n",
            "o1-mini-2024-09-12\n",
            "gpt-4.1-nano\n",
            "gpt-4o-transcribe\n",
            "gpt-4o-2024-08-06\n",
            "gpt-4.5-preview\n",
            "gpt-4.5-preview-2025-02-27\n",
            "gpt-4-turbo-preview\n",
            "gpt-4-0125-preview\n",
            "gpt-4o-realtime-preview-2024-10-01\n",
            "gpt-4-1106-preview\n",
            "gpt-3.5-turbo\n",
            "gpt-4o-mini-realtime-preview-2024-12-17\n",
            "gpt-4o-mini-audio-preview-2024-12-17\n",
            "chatgpt-4o-latest\n",
            "gpt-4o-mini-realtime-preview\n",
            "o3\n",
            "o4-mini\n",
            "gpt-4o-audio-preview-2024-12-17\n",
            "o1-pro-2025-03-19\n",
            "gpt-3.5-turbo-1106\n",
            "computer-use-preview-2025-03-11\n",
            "o1\n",
            "tts-1-1106\n",
            "gpt-4o-audio-preview-2024-10-01\n",
            "tts-1\n",
            "gpt-image-1\n",
            "o1-pro\n",
            "gpt-3.5-turbo-0125\n",
            "codex-mini-latest\n",
            "gpt-4o-mini-audio-preview\n",
            "omni-moderation-2024-09-26\n",
            "omni-moderation-latest\n",
            "o1-preview\n",
            "o1-preview-2024-09-12\n"
          ]
        }
      ],
      "source": [
        "models = openai.models.list()\n",
        "for model in models:\n",
        "    print(model.id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vgbs48AQq3M7"
      },
      "source": [
        "## Add your OpenAI API key\n",
        "\n",
        "check: https://platform.openai.com/api-keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Gu7Gpc6ZMvC"
      },
      "outputs": [],
      "source": [
        "# Make sure to set your API key\n",
        "openai.api_key = \"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mr8xJhqpRA1w"
      },
      "source": [
        "## Initialize the API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeOQCXU6VL_F",
        "outputId": "362bca27-ba06-4c7a-a16b-119a198cba06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üß† AI Assistant is ready! Type 'exit' or 'quit' to stop.\n",
            "\n",
            "User: who are u\n",
            "Assistant: I am an AI language model created by OpenAI, often referred to as ChatGPT. I'm here to help answer questions, provide information, and assist with a wide range of topics. If you have any questions or need assistance, feel free to ask!\n",
            "User: exit\n",
            "üëã Goodbye!\n"
          ]
        }
      ],
      "source": [
        "# Define the assistant model\n",
        "model = \"gpt-4o\"  # Or use \"gpt-3.5-turbo\"\n",
        "\n",
        "# Initialize conversation history\n",
        "struct = []\n",
        "\n",
        "print(\"üß† AI Assistant is ready! Type 'exit' or 'quit' to stop.\\n\")\n",
        "\n",
        "while True:\n",
        "    # Get user input\n",
        "    user_message = input(\"User: \")\n",
        "\n",
        "    # Check for exit command\n",
        "    if user_message.lower() in [\"exit\", \"quit\"]:\n",
        "        print(\"üëã Goodbye!\")\n",
        "        break\n",
        "\n",
        "    # Add user message to chat structure\n",
        "    struct.append({\"role\": \"user\", \"content\": user_message})\n",
        "\n",
        "    # Get assistant response from OpenAI\n",
        "    response = openai.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=struct\n",
        "    )\n",
        "\n",
        "    # Extract and print assistant reply\n",
        "    assistant_reply = response.choices[0].message.content.strip()\n",
        "    print(\"Assistant:\", assistant_reply)\n",
        "\n",
        "    # Add assistant reply to chat structure\n",
        "    struct.append({\"role\": \"assistant\", \"content\": assistant_reply})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QT0uXU5byCa"
      },
      "source": [
        "# Gemini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKuH1LkPb_i7",
        "outputId": "f7e5799b-d5ee-4f87-d7a2-f9e18f8c6259"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution ~angchain (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~angchain (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.24.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.169.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.4)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.11.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.13.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.4.26)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~angchain (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install google-generativeai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16zJMtnCb7A-"
      },
      "source": [
        "## Add your Gemini Key\n",
        "\n",
        "check: https://aistudio.google.com/app/apikey"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psIB57YKbx1h"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "# üîê Paste your API key here\n",
        "genai.configure(api_key=\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 971
        },
        "id": "fdKBO5fxc1R4",
        "outputId": "8a111a85-481c-4937-fbdd-b4d25a942999"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "models/embedding-gecko-001\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-pro-vision\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-1.5-pro-001\n",
            "models/gemini-1.5-pro-002\n",
            "models/gemini-1.5-pro\n",
            "models/gemini-1.5-flash-latest\n",
            "models/gemini-1.5-flash-001\n",
            "models/gemini-1.5-flash-001-tuning\n",
            "models/gemini-1.5-flash\n",
            "models/gemini-1.5-flash-002\n",
            "models/gemini-1.5-flash-8b\n",
            "models/gemini-1.5-flash-8b-001\n",
            "models/gemini-1.5-flash-8b-latest\n",
            "models/gemini-1.5-flash-8b-exp-0827\n",
            "models/gemini-1.5-flash-8b-exp-0924\n",
            "models/gemini-2.5-pro-exp-03-25\n",
            "models/gemini-2.5-pro-preview-03-25\n",
            "models/gemini-2.5-flash-preview-04-17\n",
            "models/gemini-2.5-flash-preview-05-20\n",
            "models/gemini-2.5-flash-preview-04-17-thinking\n",
            "models/gemini-2.5-pro-preview-05-06\n",
            "models/gemini-2.0-flash-exp\n",
            "models/gemini-2.0-flash\n",
            "models/gemini-2.0-flash-001\n",
            "models/gemini-2.0-flash-exp-image-generation\n",
            "models/gemini-2.0-flash-lite-001\n",
            "models/gemini-2.0-flash-lite\n",
            "models/gemini-2.0-flash-preview-image-generation\n",
            "models/gemini-2.0-flash-lite-preview-02-05\n",
            "models/gemini-2.0-flash-lite-preview\n",
            "models/gemini-2.0-pro-exp\n",
            "models/gemini-2.0-pro-exp-02-05\n",
            "models/gemini-exp-1206\n",
            "models/gemini-2.0-flash-thinking-exp-01-21\n",
            "models/gemini-2.0-flash-thinking-exp\n",
            "models/gemini-2.0-flash-thinking-exp-1219\n",
            "models/gemini-2.5-flash-preview-tts\n",
            "models/gemini-2.5-pro-preview-tts\n",
            "models/learnlm-2.0-flash-experimental\n",
            "models/gemma-3-1b-it\n",
            "models/gemma-3-4b-it\n",
            "models/gemma-3-12b-it\n",
            "models/gemma-3-27b-it\n",
            "models/gemma-3n-e4b-it\n",
            "models/embedding-001\n",
            "models/text-embedding-004\n",
            "models/gemini-embedding-exp-03-07\n",
            "models/gemini-embedding-exp\n",
            "models/aqa\n",
            "models/imagen-3.0-generate-002\n",
            "models/gemini-2.5-flash-preview-native-audio-dialog\n",
            "models/gemini-2.5-flash-exp-native-audio-thinking-dialog\n",
            "models/gemini-2.0-flash-live-001\n"
          ]
        }
      ],
      "source": [
        "models = genai.list_models()\n",
        "for model in models:\n",
        "    print(model.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "Q-sFpH4ecJcO",
        "outputId": "5bf4704b-dfdd-4848-afef-98629fc53673"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ü§ñ Gemini Flash Assistant ready! Type 'exit' to stop.\n",
            "\n",
            "User: hi are u there?\n",
            "Assistant: Yes, I'm here.  How can I help you?\n",
            "\n",
            "User: patay na ba si Nora Aunor?\n",
            "Assistant: Hindi pa namamatay si Nora Aunor.  She is still alive.\n",
            "\n",
            "User: hanggang kelan lang ba ung training data mo?\n",
            "Assistant: My training data is constantly being updated, so I don't have a specific \"cutoff\" date.  The models I use are regularly improved with new information.  However, my knowledge is not completely up-to-the-minute;  I don't have access to real-time information like breaking news or events happening as we speak.  Think of my knowledge as a very large snapshot of information up to a certain point, which is constantly being refined.\n",
            "\n",
            "User: Ngek okay, exit\n",
            "Assistant: Okay. Goodbye!\n",
            "\n",
            "User: exit\n",
            "üëã Goodbye!\n"
          ]
        }
      ],
      "source": [
        "model = genai.GenerativeModel('models/gemini-1.5-flash-latest')\n",
        "chat = model.start_chat()\n",
        "\n",
        "print(\"ü§ñ Gemini Flash Assistant ready! Type 'exit' to stop.\\n\")\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"User: \")\n",
        "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
        "        print(\"üëã Goodbye!\")\n",
        "        break\n",
        "\n",
        "    response = chat.send_message(user_input)\n",
        "    print(\"Assistant:\", response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLNAJaR2dhL3"
      },
      "source": [
        "# Claude"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eXvWe2WeH-0",
        "outputId": "ded066de-04e6-4f40-ff5a-2d42457f5928"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution ~angchain (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~angchain (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting anthropic\n",
            "  Downloading anthropic-0.52.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from anthropic) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->anthropic) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->anthropic) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.4.0)\n",
            "Downloading anthropic-0.52.0-py3-none-any.whl (286 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m286.1/286.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: Ignoring invalid distribution ~angchain (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: anthropic\n",
            "Successfully installed anthropic-0.52.0\n"
          ]
        }
      ],
      "source": [
        "!pip install anthropic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lyK81rgHeKob"
      },
      "outputs": [],
      "source": [
        "import anthropic\n",
        "\n",
        "client = anthropic.Anthropic(api_key=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_IyhUCZd3ov"
      },
      "source": [
        "## Add your Anthropic Key\n",
        "\n",
        "go to : https://console.anthropic.com/dashboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AH1wfDaNdnsG",
        "outputId": "5f979838-2c11-474c-bc88-710bbc4ef253"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ü§ñ Claude Haiku Assistant ready! Type 'exit' to stop.\n",
            "\n",
            "User: hi are u there\n",
            "Claude: Yes, I'm here. How can I assist you today?\n",
            "User: kumusta ka? patay na ba si nora aunor\n",
            "Claude: I do not have any confirmed information about the current status of Nora Aunor. Nora Aunor is a well-known and acclaimed Filipino actress, but I do not have reliable data on whether she has passed away or not. Unless there are credible news reports or official announcements about her condition, I cannot provide a definitive answer to your question. I apologize that I do not have more specific information to share.\n",
            "User: hanggang kailan ba ung training data mo?\n",
            "Claude: Hindi ko po alam ang detalye tungkol sa training data ko. Ako ay isang artificial intelligence na nilikha ng Anthropic, ngunit hindi ko alam kung hanggang kailan ang training data na ginamit sa paglikha ko. Ang aking kaalaman ay nakabase lamang sa data na naitrain sa akin, at hindi ako sigurado kung ilang panahon ang nasasakop nito. Hinihiling ko na mag-refer kayo sa mga impormasyong nakalathala ng Anthropic kung nais ninyong malaman ang mga detalye tungkol sa aking background at kakayahan.\n",
            "User: quit\n",
            "üëã Goodbye!\n"
          ]
        }
      ],
      "source": [
        "print(\"ü§ñ Claude Haiku Assistant ready! Type 'exit' to stop.\\n\")\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"User: \")\n",
        "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
        "        print(\"üëã Goodbye!\")\n",
        "        break\n",
        "\n",
        "    response = client.messages.create(\n",
        "        model=\"claude-3-haiku-20240307\",\n",
        "        max_tokens=1024,\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": user_input}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    print(\"Claude:\", response.content[0].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lt2ZsFbiQ3mI"
      },
      "source": [
        "#Finetuning Open Source"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hguEfoWkZrQb",
        "outputId": "9f76c47c-248e-4a2d-a5f0-fba2bfc46927"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üß† AI Assistant is ready! Type 'exit' to stop.\n",
            "\n",
            "User: who are u\n",
            "Assistant: Hello! I'm your friendly Python tutor, here to help you understand programming concepts and learn Python. Whether you have questions about specific programming topics or need help with examples, feel free to ask! What would you like to learn about today?\n",
            "User: exit\n",
            "üëã Goodbye!\n"
          ]
        }
      ],
      "source": [
        "# System message to guide the assistant's behavior\n",
        "system_prompt = \"\"\"\n",
        "You are a friendly Python tutor. Help users understand basic programming concepts clearly and with examples.\n",
        "\"\"\"\n",
        "\n",
        "# Conversation history\n",
        "conversation = [{\"role\": \"system\", \"content\": system_prompt}]\n",
        "\n",
        "print(\"üß† AI Assistant is ready! Type 'exit' to stop.\\n\")\n",
        "\n",
        "# Chat loop\n",
        "while True:\n",
        "    user_input = input(\"User: \")\n",
        "\n",
        "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
        "        print(\"üëã Goodbye!\")\n",
        "        break\n",
        "\n",
        "    # Add user message\n",
        "    conversation.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "    # ‚úÖ Use the new-style method call\n",
        "    response = openai.chat.completions.create(\n",
        "        model=\"gpt-4o\",  # Or use \"gpt-3.5-turbo\"\n",
        "        messages=conversation\n",
        "    )\n",
        "\n",
        "    # Get the assistant‚Äôs reply\n",
        "    reply = response.choices[0].message.content.strip()\n",
        "    print(\"Assistant:\", reply)\n",
        "\n",
        "    # Add assistant reply to the conversation\n",
        "    conversation.append({\"role\": \"assistant\", \"content\": reply})"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
